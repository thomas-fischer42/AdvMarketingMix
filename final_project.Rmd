---
title: "Untitled"
author: "Thomas Fischer"
date: "14 11 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("code/01_dependencies.R")
source("code/02_functions.R")
source("code/03_processing.R")
source("code/04_basemodel.R")
source("code/05_brandchoice.R")
source("code/06_incidence.R")
source("code/07_quantity.R")
source("code/08_combined.R")
source("code/09_segments.R")
```


# Remaining issues
- Cannot calculate standard errors
- Base price
- Optimization is slow. Further room for improvement?
  o Could limit analysis to sequential approach?


```{r}
bm <- base_model(kaffee2)
m1 <- brandChoiceModel(bm)
m2 <- incidenceModel(bm)
m3 <- quantityModel(bm)
m4 <- jointModel(bm)
m5 <- jointModelSegments(bm, 2)

optim_control <- list(maxit = 1e3)
# res1 <- optim(rep(0, 10), m1, hessian = TRUE)
# res2 <- optim(rep(0,  4), m2, method = "L-BFGS-B")
# res3 <- optim(rep(0, 11), m3)
# res4 <- optim(rep(0, 26), m4)
res5 <- optim(rep(0, 54), m5, method = "L-BFGS-B", control = optim_control)

sum(res1$hessian)

library(numDeriv)

```


```{r}
getStorePrices(kaffee) %>%
	arrange(Days) %>% 
	tidyr::pivot_longer(cols = ends_with("Price"), names_to = "Brand", values_to = "Price") %>% 
	drop_duplicates() %>% 
	filter(Price > 0) %>%
	filter(Brand == "Brand_3_Price") %>% 
	ggplot() + 
	geom_line(aes(x = Days, y = Price, group = ID_Store))


```


```{r}
getPurchaseVolume(kaffee2) %>% 
	ggplot() + 
	geom_smooth(aes(x = Days, y = Units, group = Brand, col = Brand), se = FALSE)
```




```{r}
model <- brandChoiceModel(kaffee2)
res_bch <- optim(rep(0, 11), model, return.data = FALSE, control = list(maxit = 2e4), hessian = TRUE)

out_bch <- res_bch$par + cbind(
	-qnorm(0.975) * (diag(res_bch$hessian)^-0.5), 0,
	 qnorm(0.975) * (diag(res_bch$hessian))^-0.5)
rownames(out_bch) <- c("Intercept", brand_names[-1], "Loyalty", "Last purchased", "Price", "Pricecut")
kaffee3 <- model(res_bch$par, return.data = TRUE)
round(out_bch,3)

kaffee3
```
```{r}
res_bch
```

```{r}
model <- incidenceModel(kaffee3)
res_pur <- optim(rep(0, 4), model, return.data = FALSE, control = list(maxit = 2e4), hessian = TRUE)

out_pur <- res_pur$par + cbind(
	-qnorm(0.975) * sqrt(diag(res_pur$hessian)), 0, 
	 qnorm(0.975) * sqrt(diag(res_pur$hessian)))
rownames(out_pur) <- c("Intercept", "Avg Consumption", "Inventory", "Category value")
round(out_pur,3)
```

```{r}
model <- quantityModel(kaffee2)
res_qty <- optim(rep(0, 12), model, return.data = FALSE, control = list(maxit = 2e4), hessian = TRUE)

out_qty <- res_qty$par + cbind(
	-qnorm(0.975) * (diag(res_qty$hessian))^-0.5, 0, 
	 qnorm(0.975) * (diag(res_qty$hessian))^-0.5)
rownames(out_qty) <- c("Intercept", brand_names[-1], "PR", "Inventory", "Loyalty", "Price", "Pricecut")
round(out_qty,3)
```

```{r}
start_pars <- c(res_bch$par, res_pur$par, res_qty$par)
model <- jointModel(kaffee2)
res_full <- optim(start_pars, model, control = list(maxit = 2e4), hessian = TRUE)

out_full <- res_full$par + cbind(
	-qnorm(0.975) * (diag(res_full$hessian))^-0.5, 0, 
	 qnorm(0.975) * (diag(res_full$hessian))^-0.5)
rownames(out_full) <- c(paste("BCH", rownames(out_bch)), 
												paste("PUR", rownames(out_pur)), 
												paste("Qty", rownames(out_qty)))
out_full
```

```{r}
start_pars <- rep(c(0, res_full$par), 2)
model <- jointModelSegments(kaffee2, 2)
res_seg <- optim(start_pars, model, control = list(maxit=2e4), hessian = TRUE, method = "CG")

out_seg <- res_seg$par + cbind(
	-qnorm(0.975) * (diag(res_seg$hessian))^-0.5, 0, 
	 qnorm(0.975) * (diag(res_seg$hessian))^-0.5)

rownames(out_seg) <- c("SEG1 Size", paste("SEG1", rownames(out_full)),
											 "Seg2 Size", paste("SEG2", rownames(out_full)))
```

```{r}
library(microbenchmark)

model <- quantityModel(kaffee2)

microbenchmark(model(rep(0, 11)))
```



